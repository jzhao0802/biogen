---
title: "Bayesian inference with cross validation"
author: "Norman Poh"
date: "2 November 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---
title: "Bayesian inference"
author: "Norman Poh"
date: "20 October 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Local set up

1. First, mount your data folder in Windows command prompt:
subst L: C:\Users\npoh\Documents\myProjects\Biogen_Tecfidera

2. set up local data drive
subst D: C:\Users\npoh\Documents\myProjects\Biogen_Tecfidera

```{r}
#rm(list = ls())
setwd("L:/modelling")
library(palab)
library(palabmod)
library(ggplot2)
library(tidyverse)
library(stringr)
library(lubridate)
library(tictoc)
library(hashmap)
library(xgboost)
library(R.utils)
library(ROCR)
library(pROC) # to calculate auc
library(glmnet)
library(dismo)
source_files <- list.files("F:/Lachlan/biogen_tecfidera/lib", full.names = TRUE)

for(i in c(1:15, 17:19)) {
  source(source_files[i])
}

```

```{r}

results_dir = "F:/Projects/Biogen_Tecfidera/Results/modelling_09_bayesian/"
mkdirs(results_dir)
```

## Load the original variables

```{r}
data_dir <- "F:/Projects/Biogen_Tecfidera/Data/Processed/"
combined = read_rds(paste0(data_dir, "combined_date_complied_rectified_num_gaba_copay_data.rds"))
config = read_csv(paste0(data_dir, "combined_date_complied_rectified_num_gaba_copay_config.csv"))

```

## Get the map up

```{r}
Description = hashmap(config$Column, config$Description)
var_grouping = hashmap(config$Column, config$var_grouping)
var_period = hashmap(config$Column, config$var_period)

# define this function for use later:
remove_na_table <- function(table_) {
  selected = !is.na(table_$x)
  return(table_[selected,])
}

```

## Defining the cross validation split, loading in model_prior and the list of variables
```{r}
if (TRUE) {
  combined$partition =
    readRDS(paste0(results_dir, "model/partition.rds"))
} else { # run the following for the first time only
  combined$partition = kfold(1:nrow(combined), k=5, by = combined$discontinue_flg)
  saveRDS(combined$partition,
    'D:/Results/modelling_09_bayesian/model/partition.rds')
}

kf = combined$partition

model_prior = readRDS(paste0(results_dir, "model/model_prior.rds"))
vlist = readRDS(paste0(results_dir, "model/vlist.rds"))

```
## get the logit scores
```{r}
model_indi = vector('list', 3)
logits = vector('list', 3)

# for variable sets 2 and 3, get the logit scores:
for (m in 2:3) {
  # define list of length equal to number of variables
  model_indi[[m]] = vector('list', length(vlist[[m]]))
  
  # get the model priors (there are 100)
  x = model_prior[[m]]$x_space
  
  # this is a 300 row by 3 column dataset, with x , y, and type.
  # 'type' is split into 3: llh 0, llh 1, and Prob.apriori
  # (prob-apriori is the posterior probability)
  mat_prior = inference_bayes(model_prior[[m]], x, 
      legend_label='Prob.apriori')
  
  # this is just a matrix of 0s
  logits[[m]] = matrix(0, nrow(combined), length(vlist[[m]]))
  
  # for each of the variables:
  for (i in 1:length(vlist[[m]])) {
    
    # get the variable and the outcome variable
    combined_ = combined %>% 
      dplyr::select(one_of(c(vlist[[m]][i],'discontinue_flg')))
    colnames(combined_) = c('x','label')
    
    # a list of 0s equal to the number of rows in the dataset
    column_ = rep(0, nrow(combined))
    
    # train bayes classifier on the training set (!k) and make inference on
    # the test set (k)
    for (k in 1:5) {
      # select everything outside the kth fold and remove missing values
      mat__ = remove_na_table(combined_[kf!=k,])
      
      # training (with prior model included to add robustness).
      # this object includes two likelihood functions, estimated using
      # kernel density estimation. It includes a count of the number
      # of positives and negatives in the non-missing dataset mat__, and
      model_indi_ = train_bayes(mat__$x, mat__$label, model_prior[[m]])
  
      # adaptation
      model_indi[[m]][[i]] = adapt_bayes(model_prior[[m]], 
        model_indi_, relevance_factor=100,x )
    
      # make inference on the test set k
      mat__ = combined_[kf==k,]
      # takes the log of the likelihoods
      logit_ = predict_bayes_logit(model_indi[[m]][[i]], mat__$x)
      # mat_indi_adapted = inference_bayes(model_indi[[m]][[i]], mat__$x,
      #   legend_label='Prob.Adapted')
      # mat_indi_adapted = mat_indi_adapted %>% filter(type == 'Prob.Adapted')
      # mat_indi_adapted$y
      column_[kf==k] = logit_
    }
    logits[[m]][,i] = column_
  }# for all i
} # for all m

```

## make tha mat matrix from logits data
```{r}
# how many nonzeros can we expect per column?
res_logit = as.data.frame(apply(logits[[2]], 2, function(x) {sum(!near(x, 0))}))
colnames(res_logit)='count'
res_data = as.data.frame(apply(
  combined %>% dplyr::select(one_of(vlist[[m]])), 
  2, function(x) {(sum(!is.na(x)))}))
colnames(res_data)='count'
res_logit
res_data

# put the logit scores together to form the matrix mat
# output is one matrix of logits- series of logits per variable
mat = as.data.frame(cbind(logits[[2]], logits[[3]]))
colnames(mat) = c(vlist[[2]], vlist[[3]])
colnames(mat) = str_replace(colnames(mat),'_diff','_logit')


# truncate extreme values
mat = as.data.frame( apply(mat, 2, function(x){ ifelse(x < -700, -8, x) }))

min(mat)


```
## train glm on all the data set to get the weights

```{r}
#training
target_tab = as.numeric(table(combined$discontinue_flg))
iw = 1/target_tab[as.numeric(combined$discontinue_flg)+1] 

#checking
sum(iw[combined$discontinue_flg==1])
sum(iw[combined$discontinue_flg==0])

glm_ = glmnet::glmnet(x=as.matrix(mat), y=as.factor(combined$discontinue_flg), 
  family="binomial",weights = iw)

plot(glm_, xvar = "dev", label = TRUE)

# optimise for penalisation penalty lambda
glm_cv = cv.glmnet(x=as.matrix(mat), y=as.factor(combined$discontinue_flg), 
  family="binomial",weights = iw, type.measure = "deviance")

plot(glm_cv)
glm_cv$lambda.min
glm_cv$lambda.1se

out_ = cbind( coef(glm_cv, s = "lambda.min"),
  coef(glm_cv, s = "lambda.1se"))
colnames(out_) = c('lambda.min','lambda.1se')

# takes logit scores (likelihoods) and puts them through the LR
# output is the weighted logit scores
prob_lr = predict(glm_, as.matrix(mat), type='response', 
  s=c(0.01, glm_cv$lambda.min, glm_cv$lambda.1se)) 


# select those rows that are not zeros every where
# this shows only 250 patients are affected by this analysis.
rows_ = as.data.frame( apply(mat, 1, function(x){ sum(x)  }))
selected = !near(rows_, 0)
sum(selected) # only 250 samples are affected

# Function to output logit (log of prob ratio) for a set of probabilities
logit_transform <- function(x) {
  return(log(x) - log(1-x))
}

# comparing scores and truth for these 250 patients
res = tibble(scores = logit_transform(prob_lr[selected,3]), 
  truth = as.factor(combined$discontinue_flg[selected]))

table(res$truth)

eer_ = calculate_eer(res$scores, res$truth)

ggplot(res) + aes(scores, group=truth, fill=truth) + 
    geom_density(alpha = .2) + xlab( 'logit scores' ) 
```
## optimal values found on the logit score matrix after capping the negative class to -8

                       lambda.min lambda.1se
(Intercept)            0.01255868 0.01428597
post_symps_fst8_logit  0.97610060 0.40553509
post_symps_fst10_logit 0.86789346 0.33189555
post_symps_fst12_logit 1.10787735 0.43117158
post_symps_fst13_logit 0.36262604 0.19240150
post_symps_fst14_logit 0.52062930 0.21421914
post_symps_fst15_logit 0.76898446 0.26473180
post_symps_fst16_logit 0.82319008 0.30008792
post_dme_fst_logit     0.68857199 0.38052039


## Get the PR curve based on the 250 patients affected
```{r}
# create PR curve for this model
pred <- ROCR::prediction( res$scores , res$truth)
perf <- ROCR::performance(pred,"ppv","rec")
cutoffs <- data.frame(cut=perf@alpha.values[[1]], recall=perf@x.values[[1]], 
                      precision=perf@y.values[[1]])

ggplot(cutoffs) + aes(x=recall, y=precision, xend=1, yend=1) + 
    geom_smooth(alpha = .2) + geom_point()

```
